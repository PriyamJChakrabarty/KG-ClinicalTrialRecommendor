{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Similar Clinical Trials Using Graph Embeddings (Alternative Method)\n",
    "\n",
    "This notebook uses **Custom Random Walks + TF-IDF** for graph embeddings - **NO Node2Vec, NO gensim, NO numpy issues!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries (Minimal Dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install neo4j networkx scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Connection details for LOCAL Neo4j\n",
    "URI = \"neo4j://127.0.0.1:7687\"\n",
    "AUTH = (\"neo4j\", \"12345678\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fetch Graph from Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_graph_from_neo4j(driver):\n",
    "    \"\"\"\n",
    "    Fetch the entire graph from Neo4j and convert to NetworkX\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    MATCH (n1)-[r:RELATIONSHIP]-(n2)\n",
    "    RETURN n1.name AS node1, n2.name AS node2,\n",
    "           labels(n1) AS labels1, labels(n2) AS labels2\n",
    "    \"\"\"\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        \n",
    "        print(\"Loading graph from Neo4j...\")\n",
    "        edge_count = 0\n",
    "        \n",
    "        for record in result:\n",
    "            node1 = record[\"node1\"]\n",
    "            node2 = record[\"node2\"]\n",
    "            labels1 = list(record[\"labels1\"])\n",
    "            labels2 = list(record[\"labels2\"])\n",
    "            \n",
    "            # Add nodes with their labels\n",
    "            G.add_node(node1, label=labels1[0] if labels1 else \"Unknown\")\n",
    "            G.add_node(node2, label=labels2[0] if labels2 else \"Unknown\")\n",
    "            \n",
    "            # Add edge\n",
    "            G.add_edge(node1, node2)\n",
    "            edge_count += 1\n",
    "            \n",
    "            if edge_count % 5000 == 0:\n",
    "                print(f\"Loaded {edge_count} edges...\")\n",
    "        \n",
    "        print(f\"\\n✓ Graph loaded successfully!\")\n",
    "        print(f\"Total nodes: {G.number_of_nodes()}\")\n",
    "        print(f\"Total edges: {G.number_of_edges()}\")\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Custom Random Walk Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(G, start_node, walk_length=30):\n",
    "    \"\"\"\n",
    "    Perform a single random walk starting from start_node\n",
    "    \"\"\"\n",
    "    walk = [start_node]\n",
    "    \n",
    "    for _ in range(walk_length - 1):\n",
    "        current = walk[-1]\n",
    "        neighbors = list(G.neighbors(current))\n",
    "        \n",
    "        if not neighbors:\n",
    "            break\n",
    "        \n",
    "        # Randomly choose next node\n",
    "        next_node = random.choice(neighbors)\n",
    "        walk.append(next_node)\n",
    "    \n",
    "    return walk\n",
    "\n",
    "\n",
    "def generate_walks(G, num_walks=100, walk_length=30):\n",
    "    \"\"\"\n",
    "    Generate random walks for all nodes in the graph\n",
    "    \"\"\"\n",
    "    print(f\"\\nGenerating random walks...\")\n",
    "    print(f\"Parameters: num_walks={num_walks}, walk_length={walk_length}\")\n",
    "    \n",
    "    walks = []\n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    for i, node in enumerate(nodes):\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Generated walks for {i + 1}/{len(nodes)} nodes...\")\n",
    "        \n",
    "        for _ in range(num_walks):\n",
    "            walk = random_walk(G, node, walk_length)\n",
    "            walks.append(walk)\n",
    "    \n",
    "    print(f\"✓ Generated {len(walks)} random walks!\")\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Embeddings Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_contexts(walks, G):\n",
    "    \"\"\"\n",
    "    Create context documents for each node from random walks\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating node context documents...\")\n",
    "    \n",
    "    node_contexts = {node: [] for node in G.nodes()}\n",
    "    \n",
    "    # Collect all walks for each node\n",
    "    for walk in walks:\n",
    "        for node in walk:\n",
    "            # Add all other nodes in the walk as context\n",
    "            context = [n for n in walk if n != node]\n",
    "            node_contexts[node].extend(context)\n",
    "    \n",
    "    # Convert to text documents (space-separated node names)\n",
    "    node_documents = {}\n",
    "    for node, context in node_contexts.items():\n",
    "        if context:\n",
    "            node_documents[node] = ' '.join(context)\n",
    "        else:\n",
    "            node_documents[node] = node  # Isolated nodes\n",
    "    \n",
    "    print(f\"✓ Created context documents for {len(node_documents)} nodes\")\n",
    "    return node_documents\n",
    "\n",
    "\n",
    "def generate_tfidf_embeddings(node_documents):\n",
    "    \"\"\"\n",
    "    Generate TF-IDF embeddings from node context documents\n",
    "    \"\"\"\n",
    "    print(\"\\nGenerating TF-IDF embeddings...\")\n",
    "    \n",
    "    nodes = list(node_documents.keys())\n",
    "    documents = [node_documents[node] for node in nodes]\n",
    "    \n",
    "    # Create TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    \n",
    "    # Create node to embedding mapping\n",
    "    embeddings = {}\n",
    "    for i, node in enumerate(nodes):\n",
    "        embeddings[node] = tfidf_matrix[i]\n",
    "    \n",
    "    print(f\"✓ Generated embeddings with {tfidf_matrix.shape[1]} dimensions\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Find Similar Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_nodes(G):\n",
    "    \"\"\"\n",
    "    Get all SubjectNode (clinical trial) nodes\n",
    "    \"\"\"\n",
    "    subject_nodes = [node for node, data in G.nodes(data=True) \n",
    "                     if data.get('label') == 'SubjectNode']\n",
    "    return subject_nodes\n",
    "\n",
    "\n",
    "def find_similar_trials_embedding(embeddings, G, trial_id, top_n=10):\n",
    "    \"\"\"\n",
    "    Find similar trials using cosine similarity on embeddings\n",
    "    \"\"\"\n",
    "    # Check if trial exists\n",
    "    if trial_id not in embeddings:\n",
    "        return []\n",
    "    \n",
    "    # Get all subject nodes\n",
    "    subject_nodes = get_subject_nodes(G)\n",
    "    \n",
    "    # Get embedding for the query trial\n",
    "    query_embedding = embeddings[trial_id]\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = []\n",
    "    for node in subject_nodes:\n",
    "        if node == trial_id or node not in embeddings:\n",
    "            continue\n",
    "        \n",
    "        node_embedding = embeddings[node]\n",
    "        similarity = cosine_similarity(query_embedding, node_embedding)[0][0]\n",
    "        similarities.append((node, float(similarity)))\n",
    "    \n",
    "    # Sort by similarity (descending) and return top N\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "\n",
    "def check_trial_exists(G, trial_id):\n",
    "    \"\"\"\n",
    "    Check if a trial ID exists in the graph\n",
    "    \"\"\"\n",
    "    return trial_id in G.nodes() and G.nodes[trial_id].get('label') == 'SubjectNode'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Load Graph and Generate Embeddings (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph from Neo4j\n",
    "print(\"Step 1: Loading graph from Neo4j...\")\n",
    "driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "G = fetch_graph_from_neo4j(driver)\n",
    "driver.close()\n",
    "\n",
    "# Generate random walks\n",
    "print(\"\\nStep 2: Generating random walks...\")\n",
    "walks = generate_walks(G, num_walks=50, walk_length=30)\n",
    "\n",
    "# Create node contexts\n",
    "print(\"\\nStep 3: Creating node contexts...\")\n",
    "node_documents = create_node_contexts(walks, G)\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"\\nStep 4: Generating embeddings...\")\n",
    "embeddings = generate_tfidf_embeddings(node_documents)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ READY! You can now search for similar trials.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Single Trial ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single trial example\n",
    "trial_id = \"NCT00752622\"  # Change this to any trial ID you want\n",
    "\n",
    "if not check_trial_exists(G, trial_id):\n",
    "    print(f\"Trial {trial_id} not found in database!\")\n",
    "else:\n",
    "    print(f\"Finding similar trials to {trial_id} using Graph Embeddings...\\n\")\n",
    "    \n",
    "    # Find similar trials\n",
    "    similar_trials = find_similar_trials_embedding(embeddings, G, trial_id, top_n=10)\n",
    "    \n",
    "    if similar_trials:\n",
    "        print(f\"Top 10 Similar Trials to {trial_id}:\")\n",
    "        print(\"=\" * 60)\n",
    "        for i, (similar_trial, similarity) in enumerate(similar_trials, 1):\n",
    "            print(f\"{i:2d}. {similar_trial}: {similarity:.4f}\")\n",
    "    else:\n",
    "        print(\"No similar trials found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Multiple Trial IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple trials example\n",
    "trial_ids = [\"NCT00385736\", \"NCT00386607\", \"NCT03518073\"]\n",
    "\n",
    "for trial_id in trial_ids:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Trial ID: {trial_id}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Check if trial exists\n",
    "    if not check_trial_exists(G, trial_id):\n",
    "        print(f\"Trial {trial_id} not found in database!\")\n",
    "        continue\n",
    "    \n",
    "    # Find similar trials\n",
    "    similar_trials = find_similar_trials_embedding(embeddings, G, trial_id, top_n=10)\n",
    "    \n",
    "    if similar_trials:\n",
    "        print(f\"\\nTop 10 Similar Trials:\")\n",
    "        for i, (similar_trial, similarity) in enumerate(similar_trials, 1):\n",
    "            print(f\"{i:2d}. {similar_trial}: Similarity = {similarity:.4f}\")\n",
    "    else:\n",
    "        print(\"No similar trials found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive version - get input from user\n",
    "trial_input = input(\"Enter trial ID(s) separated by commas: \")\n",
    "trial_ids = [t.strip() for t in trial_input.split(',') if t.strip()]\n",
    "\n",
    "for trial_id in trial_ids:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Trial ID: {trial_id}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Check if trial exists\n",
    "    if not check_trial_exists(G, trial_id):\n",
    "        print(f\"❌ Trial {trial_id} not found in database!\")\n",
    "        continue\n",
    "    \n",
    "    # Find similar trials\n",
    "    similar_trials = find_similar_trials_embedding(embeddings, G, trial_id, top_n=10)\n",
    "    \n",
    "    if similar_trials:\n",
    "        print(f\"\\n✓ Top 10 Similar Trials (Graph Embeddings):\")\n",
    "        for i, (similar_trial, similarity) in enumerate(similar_trials, 1):\n",
    "            print(f\"{i:2d}. {similar_trial}: Similarity = {similarity:.4f}\")\n",
    "    else:\n",
    "        print(\"No similar trials found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Jaccard Similarity (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_trials_jaccard(driver, trial_id, top_n=10):\n",
    "    \"\"\"\n",
    "    Find similar trials using Jaccard similarity (for comparison)\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    MATCH (input:SubjectNode {name: $trial_id})\n",
    "    MATCH (input)-[:RELATIONSHIP]-(inputNeighbor:ObjectNode)\n",
    "    WITH input, COLLECT(DISTINCT inputNeighbor) AS inputNeighbors\n",
    "    \n",
    "    MATCH (other:SubjectNode)\n",
    "    WHERE other <> input\n",
    "    \n",
    "    MATCH (other)-[:RELATIONSHIP]-(otherNeighbor:ObjectNode)\n",
    "    WITH input, inputNeighbors, other, COLLECT(DISTINCT otherNeighbors) AS otherNeighbors\n",
    "    \n",
    "    WITH input, other,\n",
    "         inputNeighbors,\n",
    "         otherNeighbors,\n",
    "         [n IN inputNeighbors WHERE n IN otherNeighbors] AS intersection\n",
    "    WITH input, other,\n",
    "         SIZE(intersection) AS intersectionSize,\n",
    "         SIZE(inputNeighbors) + SIZE(otherNeighbors) - SIZE(intersection) AS unionSize\n",
    "    \n",
    "    WITH other.name AS similarTrial,\n",
    "         CASE WHEN unionSize = 0 THEN 0.0 \n",
    "              ELSE toFloat(intersectionSize) / toFloat(unionSize) \n",
    "         END AS similarity\n",
    "    \n",
    "    WHERE similarity > 0\n",
    "    RETURN similarTrial, similarity\n",
    "    ORDER BY similarity DESC\n",
    "    LIMIT $top_n\n",
    "    \"\"\"\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, trial_id=trial_id, top_n=top_n)\n",
    "        return [(record[\"similarTrial\"], record[\"similarity\"]) for record in result]\n",
    "\n",
    "\n",
    "# Compare both methods\n",
    "trial_id = \"NCT00385736\"\n",
    "\n",
    "print(f\"Comparing Jaccard vs Graph Embeddings for {trial_id}\\n\")\n",
    "\n",
    "# Jaccard\n",
    "driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "jaccard_results = find_similar_trials_jaccard(driver, trial_id, top_n=10)\n",
    "driver.close()\n",
    "\n",
    "# Embeddings\n",
    "embedding_results = find_similar_trials_embedding(embeddings, G, trial_id, top_n=10)\n",
    "\n",
    "# Display side by side\n",
    "print(\"=\"*70)\n",
    "print(f\"{'JACCARD SIMILARITY':<35} | {'GRAPH EMBEDDINGS':<35}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(10):\n",
    "    jaccard_str = f\"{jaccard_results[i][0]}: {jaccard_results[i][1]:.4f}\" if i < len(jaccard_results) else \"-\"\n",
    "    embed_str = f\"{embedding_results[i][0]}: {embedding_results[i][1]:.4f}\" if i < len(embedding_results) else \"-\"\n",
    "    print(f\"{i+1:2d}. {jaccard_str:<32} | {embed_str:<32}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
